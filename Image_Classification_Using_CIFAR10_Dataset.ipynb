{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T10:03:34.394982Z",
     "start_time": "2020-11-02T10:02:23.981967Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T13:49:45.900384Z",
     "start_time": "2020-10-26T13:49:45.885385Z"
    }
   },
   "source": [
    "# The current state of the art performance for this dataset is 99 accuracy (GPipe: Efficient Training of Giant Neural Networks using pipeline parallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T10:03:34.481458Z",
     "start_time": "2020-11-02T10:03:34.434377Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T10:03:36.290054Z",
     "start_time": "2020-11-02T10:03:34.516465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4684316816424207863\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1416432436\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2852806309567360068\n",
      "physical_device_desc: \"device: 0, name: GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Setting random seed for reproducible results\n",
    "\n",
    "from tensorflow.python.client import device_lib \n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the cifar 10 dataset\n",
    "- Data downloaded from https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:06:00.462133Z",
     "start_time": "2020-11-02T12:06:00.430654Z"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "num_channels = 3\n",
    "image_size_flat = image_size * image_size * num_channels\n",
    "num_classes = 10\n",
    "train_files = 5\n",
    "image_per_file = 10000\n",
    "num_train_images = 50000\n",
    "\n",
    "# functions for processing raw cifar file from memory\n",
    "\n",
    "\n",
    "# change the raw data to float and normalize them by dividing by the highest pixel value 255\n",
    "def convert(raw):\n",
    "    raw_float = np.array(raw, dtype=float)\n",
    "    #reshape into 4 dimensions\n",
    "    images = raw_float.reshape(-1, num_channels, image_size, image_size)\n",
    "    # reorder image shape indices\n",
    "    images = images.transpose([0,2,3,1])\n",
    "    return images\n",
    "\n",
    "# load pickle files and return the images and class label\n",
    "def load(filename):\n",
    "    #load pickle files\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "    \n",
    "    # get raw images and label\n",
    "    raw_images = data[b'data']\n",
    "    labels = np.array(data[b'labels'])\n",
    "    \n",
    "    # convert the images\n",
    "    images = convert(raw_images)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# load the name of the classes in the cifar-10 dataset\n",
    "def load_class_names():\n",
    "    with open('data/batches.meta', 'rb') as f:\n",
    "        raw = pickle.load(f, encoding='bytes')[b'label_names']\n",
    "    \n",
    "    # convert from binary strings to strings\n",
    "    names = [x.decode('utf-8') for x in raw]\n",
    "    \n",
    "    return names\n",
    "\n",
    "# Load all the 5 batch files of the cifar 10 dataset and combine them in a single training dataset\n",
    "def load_train_data():\n",
    "    # create placeholder image and label arrays\n",
    "    images = np.zeros(shape=[num_train_images, image_size, image_size, num_channels], dtype='float')\n",
    "    labels = np.zeros(shape=[num_train_images], dtype='int')\n",
    "    \n",
    "    # begin index for the current batch\n",
    "    begin = 0\n",
    "    \n",
    "    # for each data file\n",
    "    for i in range(train_files):\n",
    "        # load images and labels\n",
    "        image_batch, label_batch = load('data/data_batch_' + str(i+1))\n",
    "        \n",
    "        # number of images for this batch\n",
    "        num_images = len(image_batch)\n",
    "        \n",
    "        # End-index for the current batch\n",
    "        end = begin + num_images\n",
    "        \n",
    "        # store images in an array\n",
    "        images[begin:end, :] = image_batch\n",
    "        \n",
    "        # store the labels in an array\n",
    "        labels[begin:end] = label_batch\n",
    "        \n",
    "        # the begin index is for the next batch is the current end-index\n",
    "        begin = end\n",
    "        \n",
    "    return images, labels, OneHotEncoder(sparse=False).fit_transform(labels.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# load test data\n",
    "def load_test_data():\n",
    "    images, labels = load('data/test_batch')\n",
    "    \n",
    "    return images, labels, OneHotEncoder(sparse=False).fit_transform(labels.reshape(-1, 1))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:06:02.999429Z",
     "start_time": "2020-11-02T12:06:01.367103Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "X_train, y_train, y_train_oh = load_train_data()\n",
    "X_test, y_test, y_test_oh = load_test_data()\n",
    "classes = load_class_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T11:58:49.267889Z",
     "start_time": "2020-11-02T11:58:49.255889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T10:13:12.452997Z",
     "start_time": "2020-11-02T10:13:12.393996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Alternatively\n",
    "\n",
    "#(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T10:13:12.561992Z",
     "start_time": "2020-11-02T10:13:12.549997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T10:13:12.765420Z",
     "start_time": "2020-11-02T10:13:12.691996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000,), (50000, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_train_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T10:13:20.570389Z",
     "start_time": "2020-11-02T10:13:12.865422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20f486d58c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = X_train.copy()/255\n",
    "\n",
    "plt.imshow(x[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T10:13:20.712092Z",
     "start_time": "2020-11-02T10:13:20.699064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T10:13:20.979057Z",
     "start_time": "2020-11-02T10:13:20.809059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T10:13:21.183146Z",
     "start_time": "2020-11-02T10:13:21.119433Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshaping y_train, and y_test\n",
    "y_train1 = y_train.reshape(-1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T10:13:21.793299Z",
     "start_time": "2020-11-02T10:13:21.311107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20f48bf7588>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classes[y_train[3]])\n",
    "plt.imshow(x[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After investigating the images,  we can say that the images would benefit from horizontal flip and random brightness data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:06:08.541612Z",
     "start_time": "2020-11-02T12:06:07.803871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalising the values by dividing by the maximum pixel value (255) if you loaded data from tensorflow library\n",
    "\n",
    "X_train =  X_train/255\n",
    "X_test = X_test/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use sklearn split the training data into train / validate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:06:09.821724Z",
     "start_time": "2020-11-02T12:06:08.672645Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "\n",
    "for train_index, test_index in ss.split(X_train, y_train_oh):\n",
    "    X_train, X_val = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_val = y_train_oh[train_index], y_train_oh[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:06:11.343438Z",
     "start_time": "2020-11-02T12:06:11.332482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 32, 32, 3), (5000, 32, 32, 3), (45000, 10), (5000, 10))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T12:12:48.297330Z",
     "start_time": "2020-10-30T12:12:48.225331Z"
    }
   },
   "source": [
    "### use the X_val and y_val as validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models on the train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:10:52.880816Z",
     "start_time": "2020-11-02T12:06:20.965087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_16 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 3072)              9440256   \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 12,597,258\n",
      "Trainable params: 12,597,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/40\n",
      "45000/45000 [==============================] - 19s 429us/sample - loss: 1.8733 - accuracy: 0.3294 - val_loss: 2.2020 - val_accuracy: 0.2298\n",
      "Epoch 2/40\n",
      "45000/45000 [==============================] - 19s 426us/sample - loss: 1.6728 - accuracy: 0.4060 - val_loss: 1.8553 - val_accuracy: 0.3388\n",
      "Epoch 3/40\n",
      "45000/45000 [==============================] - 19s 430us/sample - loss: 1.5845 - accuracy: 0.4387 - val_loss: 1.6614 - val_accuracy: 0.4108\n",
      "Epoch 4/40\n",
      "45000/45000 [==============================] - 19s 430us/sample - loss: 1.5239 - accuracy: 0.4603 - val_loss: 1.6722 - val_accuracy: 0.3964\n",
      "Epoch 5/40\n",
      "45000/45000 [==============================] - 19s 430us/sample - loss: 1.4780 - accuracy: 0.4775 - val_loss: 1.5599 - val_accuracy: 0.4362\n",
      "Epoch 6/40\n",
      "45000/45000 [==============================] - 19s 430us/sample - loss: 1.4316 - accuracy: 0.4939 - val_loss: 1.5354 - val_accuracy: 0.4626\n",
      "Epoch 7/40\n",
      "45000/45000 [==============================] - 19s 430us/sample - loss: 1.3909 - accuracy: 0.5100 - val_loss: 1.5613 - val_accuracy: 0.4490\n",
      "Epoch 8/40\n",
      "45000/45000 [==============================] - 20s 436us/sample - loss: 1.3552 - accuracy: 0.5223 - val_loss: 1.6284 - val_accuracy: 0.4300\n",
      "Epoch 9/40\n",
      "45000/45000 [==============================] - 20s 434us/sample - loss: 1.3226 - accuracy: 0.5357 - val_loss: 1.4824 - val_accuracy: 0.4712\n",
      "Epoch 10/40\n",
      "45000/45000 [==============================] - 19s 430us/sample - loss: 1.2941 - accuracy: 0.5451 - val_loss: 1.8873 - val_accuracy: 0.3846\n",
      "Epoch 11/40\n",
      "45000/45000 [==============================] - 19s 430us/sample - loss: 1.2647 - accuracy: 0.5543 - val_loss: 1.5009 - val_accuracy: 0.4758\n",
      "Epoch 12/40\n",
      "45000/45000 [==============================] - 20s 435us/sample - loss: 1.2324 - accuracy: 0.5679 - val_loss: 1.9744 - val_accuracy: 0.3654\n",
      "Epoch 13/40\n",
      "45000/45000 [==============================] - 19s 431us/sample - loss: 1.2079 - accuracy: 0.5779 - val_loss: 1.4927 - val_accuracy: 0.4628\n",
      "Epoch 14/40\n",
      "45000/45000 [==============================] - 19s 430us/sample - loss: 1.1778 - accuracy: 0.5879 - val_loss: 1.5290 - val_accuracy: 0.4804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20f6476b888>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(32,32,3)))\n",
    "model.add(Dense(3072, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.fit(X_train, y_train,  validation_data=[X_val, y_val], epochs=40, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:11:32.420306Z",
     "start_time": "2020-11-02T12:11:30.161210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 207us/sample - loss: 1.5203 - accuracy: 0.4728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5202577260971069, 0.4728]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_oh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T21:51:18.224673Z",
     "start_time": "2020-10-28T21:51:16.553436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.50      0.56      1000\n",
      "           1       0.80      0.31      0.45      1000\n",
      "           2       0.34      0.55      0.42      1000\n",
      "           3       0.32      0.31      0.31      1000\n",
      "           4       0.69      0.12      0.21      1000\n",
      "           5       0.36      0.50      0.42      1000\n",
      "           6       0.46      0.70      0.55      1000\n",
      "           7       0.51      0.65      0.57      1000\n",
      "           8       0.79      0.49      0.60      1000\n",
      "           9       0.50      0.64      0.56      1000\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.54      0.48      0.47     10000\n",
      "weighted avg       0.54      0.48      0.47     10000\n",
      "\n",
      "\n",
      "\n",
      "[[498   8 183  32   1  47  55  66  55  55]\n",
      " [ 40 309  30  65   2  34  63  50  34 373]\n",
      " [ 33   3 547  75  16 104 120  87   3  12]\n",
      " [  5   2 106 308   5 312 171  64   6  21]\n",
      " [ 21   2 347  63 124 106 183 137   7  10]\n",
      " [  5   1 140 173   6 502  92  64   4  13]\n",
      " [  1   1 102  84  10  69 699  24   3   7]\n",
      " [ 14   0  78  70   8 102  51 652   2  23]\n",
      " [118  25  58  37   6  70  41  30 487 128]\n",
      " [ 31  35  22  56   2  44  61  99  12 638]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = [np.argmax(x) for x in pred]\n",
    "print(classification_report(y_test, pred))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The artificial neural network preformed poorly on the test data getting 48 percent accuracy. It performed best on class 8 (ship) and worst on class 4 (deer). Next we would try a convolution neural network which is more suited to images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T15:43:34.725515Z",
     "start_time": "2020-11-01T15:43:34.707524Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "\n",
    "# zca_whitening=True\n",
    "\n",
    "#datagen.fit(X_train, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:19:42.252627Z",
     "start_time": "2020-11-02T12:17:10.899192Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 687,338\n",
      "Trainable params: 687,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None \n",
      "\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/40\n",
      "45000/45000 [==============================] - 12s 257us/sample - loss: 1.6194 - accuracy: 0.4048 - val_loss: 1.4221 - val_accuracy: 0.4840\n",
      "Epoch 2/40\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 1.2069 - accuracy: 0.5644 - val_loss: 1.0848 - val_accuracy: 0.6168\n",
      "Epoch 3/40\n",
      "45000/45000 [==============================] - 11s 237us/sample - loss: 1.0241 - accuracy: 0.6359 - val_loss: 0.9675 - val_accuracy: 0.6668\n",
      "Epoch 4/40\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 0.9034 - accuracy: 0.6816 - val_loss: 0.8921 - val_accuracy: 0.6868\n",
      "Epoch 5/40\n",
      "45000/45000 [==============================] - 11s 237us/sample - loss: 0.8104 - accuracy: 0.7148 - val_loss: 0.8465 - val_accuracy: 0.7032\n",
      "Epoch 6/40\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 0.7253 - accuracy: 0.7440 - val_loss: 0.8360 - val_accuracy: 0.7090\n",
      "Epoch 7/40\n",
      "45000/45000 [==============================] - 11s 241us/sample - loss: 0.6654 - accuracy: 0.7648 - val_loss: 0.7975 - val_accuracy: 0.7232\n",
      "Epoch 8/40\n",
      "45000/45000 [==============================] - 11s 237us/sample - loss: 0.6054 - accuracy: 0.7883 - val_loss: 0.7851 - val_accuracy: 0.7368\n",
      "Epoch 9/40\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 0.5376 - accuracy: 0.8116 - val_loss: 0.7849 - val_accuracy: 0.7348\n",
      "Epoch 10/40\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 0.4963 - accuracy: 0.8250 - val_loss: 0.8258 - val_accuracy: 0.7156\n",
      "Epoch 11/40\n",
      "45000/45000 [==============================] - 11s 239us/sample - loss: 0.4411 - accuracy: 0.8447 - val_loss: 0.8334 - val_accuracy: 0.7396\n",
      "Epoch 12/40\n",
      "45000/45000 [==============================] - 11s 239us/sample - loss: 0.3970 - accuracy: 0.8616 - val_loss: 0.8370 - val_accuracy: 0.7472\n",
      "Epoch 13/40\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 0.3592 - accuracy: 0.8735 - val_loss: 0.8705 - val_accuracy: 0.7330\n",
      "Epoch 14/40\n",
      "45000/45000 [==============================] - 11s 241us/sample - loss: 0.3198 - accuracy: 0.8872 - val_loss: 0.9246 - val_accuracy: 0.7372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20f66eb0848>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "cnn = Sequential()\n",
    "\n",
    "# data augumentation\n",
    "# cnn.add(preprocessing.RandomFlip('horizontal')) # flip left to right\n",
    "# cnn.add(preprocessing.RandomContrast(0.5)) # contrast change by up to 50%\n",
    "\n",
    "# convolution layer\n",
    "cnn.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\n",
    "               padding='same', input_shape=(32, 32, 3)))\n",
    "cnn.add(MaxPool2D((2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "               activation='relu', padding='same'))\n",
    "cnn.add(MaxPool2D((2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "               activation='relu', padding='same'))\n",
    "cnn.add(MaxPool2D((2, 2)))\n",
    "\n",
    "# DNN classifier layer\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(512, activation='relu'))\n",
    "cnn.add(Dropout(0.2))\n",
    "\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "cnn.add(Dropout(0.2))\n",
    "\n",
    "# cnn.add(BatchNormalization())\n",
    "\n",
    "cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "print(cnn.summary(), '\\n')\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss')\n",
    "cnn.fit(X_train, y_train, batch_size=128, validation_data=[X_val, y_val], callbacks=[es], epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:19:50.605888Z",
     "start_time": "2020-11-02T12:19:48.375469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.9532 - accuracy: 0.7284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9532061398506164, 0.7284]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test, y_test_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "- CNN Base Accuracy: 0.7165, loss: 0.9423 (with valid padding) \n",
    "- with same padding, Accuracy: 0.7498 , loss: 1.1980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T11:24:01.648518Z",
     "start_time": "2020-11-02T11:23:59.898784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.0831444e-03, 6.2974142e-03, 4.1727073e-02, ..., 1.3908591e-02,\n",
       "        4.9401369e-02, 3.7941639e-03],\n",
       "       [9.7291086e-06, 9.9668568e-01, 1.3140768e-11, ..., 1.4708816e-12,\n",
       "        1.6313447e-02, 2.2943712e-05],\n",
       "       [9.1973983e-02, 4.5206195e-01, 7.2195871e-05, ..., 9.8815850e-05,\n",
       "        1.0513750e-01, 2.6250675e-01],\n",
       "       ...,\n",
       "       [1.4018295e-07, 1.7940168e-08, 2.0776486e-01, ..., 1.0609363e-02,\n",
       "        7.5108817e-09, 1.4930369e-07],\n",
       "       [1.0560503e-03, 1.4082702e-01, 7.4496299e-02, ..., 9.7728455e-03,\n",
       "        7.3303767e-05, 1.6160958e-04],\n",
       "       [5.7247003e-09, 3.8489226e-08, 6.2935928e-06, ..., 9.9653107e-01,\n",
       "        5.1231388e-09, 1.1388489e-08]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = cnn.predict(X_test)\n",
    "\n",
    "for x in pred:\n",
    "    for y in x:\n",
    "        check = 0\n",
    "        if y > 0:\n",
    "            check=y\n",
    "    x = x/check\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T11:25:26.813882Z",
     "start_time": "2020-11-02T11:25:25.353659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76      1000\n",
      "           1       0.83      0.85      0.84      1000\n",
      "           2       0.58      0.70      0.63      1000\n",
      "           3       0.61      0.49      0.54      1000\n",
      "           4       0.73      0.63      0.67      1000\n",
      "           5       0.63      0.67      0.65      1000\n",
      "           6       0.88      0.71      0.79      1000\n",
      "           7       0.74      0.81      0.77      1000\n",
      "           8       0.81      0.86      0.83      1000\n",
      "           9       0.84      0.79      0.81      1000\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.73     10000\n",
      "weighted avg       0.74      0.73      0.73     10000\n",
      "\n",
      "\n",
      "\n",
      "[[813  18  43   9   9   9   6  15  57  21]\n",
      " [ 16 852  12   8   3   6   4   2  34  63]\n",
      " [ 82   5 699  33  57  52  18  31  16   7]\n",
      " [ 40  14 105 495  50 185  27  46  20  18]\n",
      " [ 36   6 115  55 629  34  19  94  10   2]\n",
      " [ 18   5  83 104  28 670  12  63  11   6]\n",
      " [ 11  11  82  70  47  32 714  13  14   6]\n",
      " [ 18   3  32  25  35  62   4 805   5  11]\n",
      " [ 65  28  17   7   4   5   1   4 858  11]\n",
      " [ 40  86  14  11   3   8   2  14  37 785]]\n"
     ]
    }
   ],
   "source": [
    "pred1 = cnn.predict(X_test)\n",
    "cnn.\n",
    "#y_test_oh = [np.argmax(x) for x in y_test_oh]\n",
    "pred1 = [np.argmax(x) for x in pred]\n",
    "print(classification_report(y_test, pred1))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What i noticed is that our cnn classifier performed much better than our ann classifier(71 percent vs 48 percent accuracy). It also performed better on certain image classes and less on others\n",
    "- It performed best on image class 1 (automobile)\n",
    "- it performed performed the least on image class 3 (cat)\n",
    "\n",
    "Comparing the two models,  they both performed well on class 8(ship) and poorly on class 3(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using transfer learning with VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:26:52.289628Z",
     "start_time": "2020-11-02T12:26:48.773317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the data\n",
    "\n",
    "X_train, y_train, y_train_oh = load_train_data()\n",
    "X_test, y_test, y_test_oh = load_test_data()\n",
    "\n",
    "# Preprocess the data\n",
    "\n",
    "def preprocess(X, y):\n",
    "    X = X.astype('float32')\n",
    "    #using preprocess VGG16 method by default to scale images and their values\n",
    "    X = preprocess_input(X)\n",
    "    # changind labels to one-hot representation\n",
    "    y = tf.keras.utils.to_categorical(y, 10)\n",
    "    return (X, y)\n",
    "\n",
    "X_train, y_train = preprocess(X_train, y_train)\n",
    "X_test, y_test = preprocess(X_test, y_test)\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "\n",
    "for train_index, test_index in ss.split(X_train, y_train):\n",
    "    X_train, X_val = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_val = y_train_oh[train_index], y_train_oh[test_index]\n",
    "\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:23:25.922344Z",
     "start_time": "2020-11-02T12:23:24.259271Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the base of vgg16\n",
    "\n",
    "pt_base = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=False, weights='imagenet', pooling='max', input_shape=(32, 32, 3))\n",
    "\n",
    "#pt_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T15:43:14.471398Z",
     "start_time": "2020-11-02T12:29:11.928193Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_1:0\", shape=(None, 32, 32, 3), dtype=float32) for input (None, 32, 32, 3), but it was re-called on a Tensor with incompatible shape (None, 64, 64, 3).\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_1:0\", shape=(None, 32, 32, 3), dtype=float32) for input (None, 32, 32, 3), but it was re-called on a Tensor with incompatible shape (None, 64, 64, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_1:0\", shape=(None, 32, 32, 3), dtype=float32) for input (None, 32, 32, 3), but it was re-called on a Tensor with incompatible shape (None, 64, 64, 3).\n",
      "44928/45000 [============================>.] - ETA: 0s - loss: 2.2713 - accuracy: 0.1768WARNING:tensorflow:Model was constructed with shape Tensor(\"input_1:0\", shape=(None, 32, 32, 3), dtype=float32) for input (None, 32, 32, 3), but it was re-called on a Tensor with incompatible shape (None, 64, 64, 3).\n",
      "45000/45000 [==============================] - 467s 10ms/sample - loss: 2.2705 - accuracy: 0.1771 - val_loss: 1.8703 - val_accuracy: 0.2336\n",
      "Epoch 2/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 1.6295 - accuracy: 0.3630 - val_loss: 1.2693 - val_accuracy: 0.5286\n",
      "Epoch 3/40\n",
      "45000/45000 [==============================] - 467s 10ms/sample - loss: 1.2065 - accuracy: 0.5622 - val_loss: 0.9604 - val_accuracy: 0.6532\n",
      "Epoch 4/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.9688 - accuracy: 0.6586 - val_loss: 0.9250 - val_accuracy: 0.6704\n",
      "Epoch 5/40\n",
      "45000/45000 [==============================] - 462s 10ms/sample - loss: 0.8206 - accuracy: 0.7166 - val_loss: 0.7710 - val_accuracy: 0.7252\n",
      "Epoch 6/40\n",
      "45000/45000 [==============================] - 462s 10ms/sample - loss: 0.7140 - accuracy: 0.7565 - val_loss: 0.7787 - val_accuracy: 0.7444\n",
      "Epoch 7/40\n",
      "45000/45000 [==============================] - 463s 10ms/sample - loss: 0.6312 - accuracy: 0.7852 - val_loss: 0.7249 - val_accuracy: 0.7532\n",
      "Epoch 8/40\n",
      "45000/45000 [==============================] - 464s 10ms/sample - loss: 0.5731 - accuracy: 0.8088 - val_loss: 0.6665 - val_accuracy: 0.7758\n",
      "Epoch 9/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.5272 - accuracy: 0.8246 - val_loss: 0.6309 - val_accuracy: 0.7898\n",
      "Epoch 10/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.4810 - accuracy: 0.8405 - val_loss: 0.6306 - val_accuracy: 0.7928\n",
      "Epoch 11/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.4404 - accuracy: 0.8556 - val_loss: 0.6248 - val_accuracy: 0.7950\n",
      "Epoch 12/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.3996 - accuracy: 0.8665 - val_loss: 0.6547 - val_accuracy: 0.7898\n",
      "Epoch 13/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.3877 - accuracy: 0.8728 - val_loss: 0.6198 - val_accuracy: 0.7994\n",
      "Epoch 14/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.3931 - accuracy: 0.8726 - val_loss: 0.6672 - val_accuracy: 0.7890\n",
      "Epoch 15/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.3534 - accuracy: 0.8853 - val_loss: 0.6179 - val_accuracy: 0.8116\n",
      "Epoch 16/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.3364 - accuracy: 0.8910 - val_loss: 0.6373 - val_accuracy: 0.8114\n",
      "Epoch 17/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.3220 - accuracy: 0.8965 - val_loss: 0.6845 - val_accuracy: 0.7936\n",
      "Epoch 18/40\n",
      "45000/45000 [==============================] - 467s 10ms/sample - loss: 0.3319 - accuracy: 0.8961 - val_loss: 0.6344 - val_accuracy: 0.8158\n",
      "Epoch 19/40\n",
      "45000/45000 [==============================] - 467s 10ms/sample - loss: 0.3173 - accuracy: 0.8972 - val_loss: 0.7062 - val_accuracy: 0.8000\n",
      "Epoch 20/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.3178 - accuracy: 0.9006 - val_loss: 0.6568 - val_accuracy: 0.8184\n",
      "Epoch 21/40\n",
      "45000/45000 [==============================] - 467s 10ms/sample - loss: 0.3077 - accuracy: 0.9029 - val_loss: 0.6484 - val_accuracy: 0.8104\n",
      "Epoch 22/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.3070 - accuracy: 0.9032 - val_loss: 0.6564 - val_accuracy: 0.8258\n",
      "Epoch 23/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.2924 - accuracy: 0.9094 - val_loss: 0.6896 - val_accuracy: 0.8186\n",
      "Epoch 24/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.2902 - accuracy: 0.9089 - val_loss: 0.6943 - val_accuracy: 0.8050\n",
      "Epoch 25/40\n",
      "45000/45000 [==============================] - 466s 10ms/sample - loss: 0.2950 - accuracy: 0.9081 - val_loss: 0.7960 - val_accuracy: 0.7986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20f67132dc8>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attach the head\n",
    "\n",
    "tf_model = Sequential()\n",
    "tf_model.add(tf.keras.layers.UpSampling2D())\n",
    "\n",
    "tf_model.add(pt_base)\n",
    "\n",
    "tf_model.add(Flatten())\n",
    "\n",
    "tf_model.add(Dense(512, activation='relu'))\n",
    "tf_model.add(Dropout(0.2))\n",
    "#tf_model.add(BatchNormalization())\n",
    "\n",
    "tf_model.add(Dense(256, activation='relu'))\n",
    "tf_model.add(Dropout(0.2))\n",
    "#tf_model.add(BatchNormalization())\n",
    "\n",
    "tf_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#print(tf_model.summary())\n",
    "\n",
    "tf_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_loss')\n",
    "tf_model.fit(X_train, y_train, batch_size=128, validation_data=[X_val, y_val], callbacks=[es], epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T15:45:20.263065Z",
     "start_time": "2020-11-02T15:44:39.176540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_1:0\", shape=(None, 32, 32, 3), dtype=float32) for input (None, 32, 32, 3), but it was re-called on a Tensor with incompatible shape (None, 64, 64, 3).\n",
      "10000/10000 [==============================] - 39s 4ms/sample - loss: 0.7992 - accuracy: 0.7999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7992437379837036, 0.7999]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "- using a pretrained base - accuracy: 0.9413, loss: 0.1659\n",
    "- using an untrained base - accuracy: 0.80, loss: 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T15:50:25.187007Z",
     "start_time": "2020-11-02T15:49:48.274864Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-84c003ba95f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpred2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   1927\u001b[0m     \"\"\"\n\u001b[0;32m   1928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1929\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1931\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 91\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "pred2 = tf_model.predict(X_test)\n",
    "\n",
    "pred2 = [np.argmax(x) for x in pred2]\n",
    "\n",
    "print(classification_report(y_test, pred2))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T05:36:14.595946Z",
     "start_time": "2020-11-02T05:36:14.555949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4638460e-03, 4.7984677e-03, 6.9234386e-02, 8.8135773e-01,\n",
       "        2.9722152e-03, 8.5631832e-02, 1.9329368e-03, 4.8492029e-03,\n",
       "        2.9388447e-03, 8.5422471e-03],\n",
       "       [1.9221329e-06, 6.6483831e-06, 1.7318740e-11, 1.5293489e-09,\n",
       "        1.0368213e-11, 1.3760970e-09, 8.2767448e-10, 7.4970976e-13,\n",
       "        9.9999678e-01, 2.1126366e-06],\n",
       "       [1.0045807e-07, 1.0694215e-07, 4.3051267e-11, 1.8041608e-07,\n",
       "        1.0883047e-08, 1.4120174e-09, 5.0609461e-11, 1.1546304e-10,\n",
       "        9.9999964e-01, 1.7983822e-07],\n",
       "       [9.9459249e-01, 2.6554329e-04, 5.2526998e-06, 5.7255529e-05,\n",
       "        6.8589194e-05, 1.4273588e-05, 4.1288608e-06, 4.9162081e-06,\n",
       "        9.0581095e-03, 2.6577491e-02],\n",
       "       [1.5259470e-06, 1.8828603e-05, 8.5450336e-03, 6.3157082e-03,\n",
       "        2.1594062e-03, 2.4105785e-04, 9.7402829e-01, 1.1041429e-05,\n",
       "        2.7482001e-06, 3.0972474e-06]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pred2 = tf_model.predict(X_test)\n",
    "pred2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T05:37:14.892608Z",
     "start_time": "2020-11-02T05:37:14.852612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu]",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
