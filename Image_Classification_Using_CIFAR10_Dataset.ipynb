{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image_Classification_Using_CIFAR10_Dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chizzy-codes/CIFAR_10_Image_Classification_Project/blob/master/Image_Classification_Using_CIFAR10_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKXW_TYCrDk_",
        "outputId": "dcbfbdba-602a-4a76-ec75-74fa0f679f0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# needs to be run on colab or kaggle notebook\n",
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.33.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBV-fDpxrAzI"
      },
      "source": [
        "# Importing the needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:51:00.132910Z",
          "start_time": "2020-11-05T17:49:04.111536Z"
        },
        "id": "JrhrnQc1rAzK"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-26T13:49:45.900384Z",
          "start_time": "2020-10-26T13:49:45.885385Z"
        },
        "id": "4c2PZo9TrAzU"
      },
      "source": [
        "# The current state of the art performance for this dataset is 99 accuracy (GPipe: Efficient Training of Giant Neural Networks using pipeline parallelism)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:51:00.213795Z",
          "start_time": "2020-11-05T17:51:00.175346Z"
        },
        "id": "XGu4nwQ5rAzW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:51:24.093053Z",
          "start_time": "2020-11-05T17:51:00.248559Z"
        },
        "id": "uIPg-lXMrAzb",
        "outputId": "f710585e-88a2-4a2b-e97b-662ac0480f5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Setting random seed for reproducible results\n",
        "\n",
        "from tensorflow.python.client import device_lib \n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 8782620242756002389\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 5802259631726605253\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 18095471703029348698\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14613293312\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 5863395658410371058\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srUyiC0-rAzj"
      },
      "source": [
        "# Importing the cifar 10 dataset\n",
        "- Data downloaded from https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:51:55.005004Z",
          "start_time": "2020-11-05T17:51:54.941974Z"
        },
        "id": "VHLVRF1VrAzk"
      },
      "source": [
        "image_size = 32\n",
        "num_channels = 3\n",
        "image_size_flat = image_size * image_size * num_channels\n",
        "num_classes = 10\n",
        "train_files = 5\n",
        "image_per_file = 10000\n",
        "num_train_images = 50000\n",
        "\n",
        "# functions for processing raw cifar file from memory\n",
        "\n",
        "\n",
        "# change the raw data to float and normalize them by dividing by the highest pixel value 255\n",
        "def convert(raw):\n",
        "    raw_float = np.array(raw, dtype=float)\n",
        "    #reshape into 4 dimensions\n",
        "    images = raw_float.reshape(-1, num_channels, image_size, image_size)\n",
        "    # reorder image shape indices\n",
        "    images = images.transpose([0,2,3,1])\n",
        "    return images\n",
        "\n",
        "# load pickle files and return the images and class label\n",
        "def load(filename):\n",
        "    #load pickle files\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = pickle.load(f, encoding='bytes')\n",
        "    \n",
        "    # get raw images and label\n",
        "    raw_images = data[b'data']\n",
        "    labels = np.array(data[b'labels'])\n",
        "    \n",
        "    # convert the images\n",
        "    images = convert(raw_images)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "# load the name of the classes in the cifar-10 dataset\n",
        "def load_class_names():\n",
        "    with open('data/batches.meta', 'rb') as f:\n",
        "        raw = pickle.load(f, encoding='bytes')[b'label_names']\n",
        "    \n",
        "    # convert from binary strings to strings\n",
        "    names = [x.decode('utf-8') for x in raw]\n",
        "    \n",
        "    return names\n",
        "\n",
        "# Load all the 5 batch files of the cifar 10 dataset and combine them in a single training dataset\n",
        "def load_train_data():\n",
        "    # create placeholder image and label arrays\n",
        "    images = np.zeros(shape=[num_train_images, image_size, image_size, num_channels], dtype='float')\n",
        "    labels = np.zeros(shape=[num_train_images], dtype='int')\n",
        "    \n",
        "    # begin index for the current batch\n",
        "    begin = 0\n",
        "    \n",
        "    # for each data file\n",
        "    for i in range(train_files):\n",
        "        # load images and labels\n",
        "        image_batch, label_batch = load('data/data_batch_' + str(i+1))\n",
        "        \n",
        "        # number of images for this batch\n",
        "        num_images = len(image_batch)\n",
        "        \n",
        "        # End-index for the current batch\n",
        "        end = begin + num_images\n",
        "        \n",
        "        # store images in an array\n",
        "        images[begin:end, :] = image_batch\n",
        "        \n",
        "        # store the labels in an array\n",
        "        labels[begin:end] = label_batch\n",
        "        \n",
        "        # the begin index is for the next batch is the current end-index\n",
        "        begin = end\n",
        "        \n",
        "    return images, labels, OneHotEncoder(sparse=False).fit_transform(labels.reshape(-1, 1))\n",
        "\n",
        "\n",
        "# load test data\n",
        "def load_test_data():\n",
        "    images, labels = load('data/test_batch')\n",
        "    \n",
        "    return images, labels, OneHotEncoder(sparse=False).fit_transform(labels.reshape(-1, 1))        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:52:04.853048Z",
          "start_time": "2020-11-05T17:52:00.667099Z"
        },
        "id": "4gnhMrDurAzv"
      },
      "source": [
        "# load data\n",
        "\n",
        "X_train, y_train, y_train_oh = load_train_data()\n",
        "X_test, y_test, y_test_oh = load_test_data()\n",
        "classes = load_class_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:52:10.127120Z",
          "start_time": "2020-11-05T17:52:10.111449Z"
        },
        "id": "eSsV8ICErAz5",
        "outputId": "a0a84b79-e6b6-4cbd-ac0e-9040a98a6a7f"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (10000, 32, 32, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:52:12.652298Z",
          "start_time": "2020-11-05T17:52:11.633421Z"
        },
        "id": "arD-Cjy5rAz-",
        "outputId": "a1152646-cf31-44e2-91e6-8dda31386f9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Alternatively u can load the cifar10 dataset using keras dataset \n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:52:17.795987Z",
          "start_time": "2020-11-05T17:52:17.783980Z"
        },
        "id": "cNuE9prRrA0G",
        "outputId": "21b027c4-9a5d-459c-ae3a-545ab4bc4f8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:52:19.732231Z",
          "start_time": "2020-11-05T17:52:19.696178Z"
        },
        "id": "9vOflPYIrA0M",
        "outputId": "4ff79533-929d-45be-f272-db5b54ca101b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 1), (10000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:52:24.518717Z",
          "start_time": "2020-11-05T17:52:22.570010Z"
        },
        "id": "N-FXvSFWrA0W",
        "outputId": "f68ea569-b74b-40d1-fe2f-494d31276fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "x = X_train.copy()/255\n",
        "\n",
        "plt.imshow(x[7])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1cc20f5c688>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:52:25.431229Z",
          "start_time": "2020-11-05T17:52:25.405224Z"
        },
        "id": "zfh1JeW8rA0b",
        "outputId": "ba757ad5-6331-4b1e-a3a3-e1b18a6bae9b"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:52:27.105580Z",
          "start_time": "2020-11-05T17:52:27.076578Z"
        },
        "id": "-BxdkfLmrA0g",
        "outputId": "fa421504-a951-44f6-addf-58b537ed724e"
      },
      "source": [
        "y_train[4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:52:29.601901Z",
          "start_time": "2020-11-05T17:52:29.575916Z"
        },
        "id": "iS8YaaI8rA0m"
      },
      "source": [
        "# Reshaping y_train, and y_test\n",
        "y_train1 = y_train.reshape(-1,)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:54:07.107424Z",
          "start_time": "2020-11-05T17:54:07.075406Z"
        },
        "id": "Sa0G625y0HHe",
        "outputId": "b95d2042-ffc2-4f0e-e3ab-7c89180fd7db"
      },
      "source": [
        "classes = ['airplane',\n",
        " 'automobile',\n",
        " 'bird',\n",
        " 'cat',\n",
        " 'deer',\n",
        " 'dog',\n",
        " 'frog',\n",
        " 'horse',\n",
        " 'ship',\n",
        " 'truck']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:54:50.151874Z",
          "start_time": "2020-11-05T17:54:49.809138Z"
        },
        "id": "u6RhqchtrA0t",
        "outputId": "efb01fcf-4042-4e04-8d5b-caad779b5bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "print(classes[y_train1[3]])\n",
        "plt.imshow(x[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1cc2826cbc8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKiDMncmrA0y"
      },
      "source": [
        "# After investigating the images,  we can say that the images would benefit from horizontal flip and random brightness data augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:55:04.987973Z",
          "start_time": "2020-11-05T17:55:04.227507Z"
        },
        "id": "VzMX0H65rA0z"
      },
      "source": [
        "# Normalising the values by dividing by the maximum pixel value (255) if you loaded data from tensorflow library\n",
        "\n",
        "X_train =  X_train/255\n",
        "X_test = X_test/255\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:55:19.352178Z",
          "start_time": "2020-11-05T17:55:19.336133Z"
        },
        "id": "VrctLBW6sQBN"
      },
      "source": [
        "# converting the labels values to one hot encoded values\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5Vrk19urA03"
      },
      "source": [
        "## Use sklearn split the training data into train / validate datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:55:24.626416Z",
          "start_time": "2020-11-05T17:55:22.312485Z"
        },
        "id": "KJX_nEGErA04"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
        "\n",
        "for train_index, test_index in ss.split(X_train, y_train):\n",
        "    X_train, X_val = X_train[train_index], X_train[test_index]\n",
        "    y_train, y_val = y_train[train_index], y_train[test_index]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:55:24.891861Z",
          "start_time": "2020-11-05T17:55:24.866866Z"
        },
        "id": "Jr73MZGqrA07",
        "outputId": "53fdd965-8c36-4f15-c72c-e869e8a247da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((45000, 32, 32, 3), (5000, 32, 32, 3), (45000, 10), (5000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-30T12:12:48.297330Z",
          "start_time": "2020-10-30T12:12:48.225331Z"
        },
        "id": "ei_n7hgNrA0-"
      },
      "source": [
        "### use the X_val and y_val as validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30kVVgvTrA0_"
      },
      "source": [
        "# Training models on the train and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9GriaXerA1A"
      },
      "source": [
        "## Using an Artificial Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:10:52.880816Z",
          "start_time": "2020-11-02T12:06:20.965087Z"
        },
        "id": "Hj0Xnw6wrA1A",
        "outputId": "510b3953-f479-417f-b73f-84db7a8cd2e9"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(32,32,3)))\n",
        "model.add(Dense(3072, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "model.fit(X_train, y_train,  validation_data=[X_val, y_val], epochs=40, callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_16 (Flatten)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 3072)              9440256   \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 1024)              3146752   \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 12,597,258\n",
            "Trainable params: 12,597,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/40\n",
            "45000/45000 [==============================] - 19s 429us/sample - loss: 1.8733 - accuracy: 0.3294 - val_loss: 2.2020 - val_accuracy: 0.2298\n",
            "Epoch 2/40\n",
            "45000/45000 [==============================] - 19s 426us/sample - loss: 1.6728 - accuracy: 0.4060 - val_loss: 1.8553 - val_accuracy: 0.3388\n",
            "Epoch 3/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.5845 - accuracy: 0.4387 - val_loss: 1.6614 - val_accuracy: 0.4108\n",
            "Epoch 4/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.5239 - accuracy: 0.4603 - val_loss: 1.6722 - val_accuracy: 0.3964\n",
            "Epoch 5/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.4780 - accuracy: 0.4775 - val_loss: 1.5599 - val_accuracy: 0.4362\n",
            "Epoch 6/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.4316 - accuracy: 0.4939 - val_loss: 1.5354 - val_accuracy: 0.4626\n",
            "Epoch 7/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.3909 - accuracy: 0.5100 - val_loss: 1.5613 - val_accuracy: 0.4490\n",
            "Epoch 8/40\n",
            "45000/45000 [==============================] - 20s 436us/sample - loss: 1.3552 - accuracy: 0.5223 - val_loss: 1.6284 - val_accuracy: 0.4300\n",
            "Epoch 9/40\n",
            "45000/45000 [==============================] - 20s 434us/sample - loss: 1.3226 - accuracy: 0.5357 - val_loss: 1.4824 - val_accuracy: 0.4712\n",
            "Epoch 10/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.2941 - accuracy: 0.5451 - val_loss: 1.8873 - val_accuracy: 0.3846\n",
            "Epoch 11/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.2647 - accuracy: 0.5543 - val_loss: 1.5009 - val_accuracy: 0.4758\n",
            "Epoch 12/40\n",
            "45000/45000 [==============================] - 20s 435us/sample - loss: 1.2324 - accuracy: 0.5679 - val_loss: 1.9744 - val_accuracy: 0.3654\n",
            "Epoch 13/40\n",
            "45000/45000 [==============================] - 19s 431us/sample - loss: 1.2079 - accuracy: 0.5779 - val_loss: 1.4927 - val_accuracy: 0.4628\n",
            "Epoch 14/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.1778 - accuracy: 0.5879 - val_loss: 1.5290 - val_accuracy: 0.4804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x20f6476b888>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:11:32.420306Z",
          "start_time": "2020-11-02T12:11:30.161210Z"
        },
        "id": "caziHbNhrA1E",
        "outputId": "390fa4bc-d57a-4476-cabd-dd7ca69a9298"
      },
      "source": [
        "model.evaluate(X_test, y_test_oh) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 207us/sample - loss: 1.5203 - accuracy: 0.4728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5202577260971069, 0.4728]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-28T21:51:18.224673Z",
          "start_time": "2020-10-28T21:51:16.553436Z"
        },
        "id": "TtZxTDD5rA1I",
        "outputId": "e0901ab6-9a4b-49e0-953e-f10f25edcc02"
      },
      "source": [
        "pred = model.predict(X_test)\n",
        "pred = [np.argmax(x) for x in pred]\n",
        "print(classification_report(y_test, pred))\n",
        "print('\\n')\n",
        "print(confusion_matrix(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.50      0.56      1000\n",
            "           1       0.80      0.31      0.45      1000\n",
            "           2       0.34      0.55      0.42      1000\n",
            "           3       0.32      0.31      0.31      1000\n",
            "           4       0.69      0.12      0.21      1000\n",
            "           5       0.36      0.50      0.42      1000\n",
            "           6       0.46      0.70      0.55      1000\n",
            "           7       0.51      0.65      0.57      1000\n",
            "           8       0.79      0.49      0.60      1000\n",
            "           9       0.50      0.64      0.56      1000\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.54      0.48      0.47     10000\n",
            "weighted avg       0.54      0.48      0.47     10000\n",
            "\n",
            "\n",
            "\n",
            "[[498   8 183  32   1  47  55  66  55  55]\n",
            " [ 40 309  30  65   2  34  63  50  34 373]\n",
            " [ 33   3 547  75  16 104 120  87   3  12]\n",
            " [  5   2 106 308   5 312 171  64   6  21]\n",
            " [ 21   2 347  63 124 106 183 137   7  10]\n",
            " [  5   1 140 173   6 502  92  64   4  13]\n",
            " [  1   1 102  84  10  69 699  24   3   7]\n",
            " [ 14   0  78  70   8 102  51 652   2  23]\n",
            " [118  25  58  37   6  70  41  30 487 128]\n",
            " [ 31  35  22  56   2  44  61  99  12 638]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYKOgeOFrA1M"
      },
      "source": [
        "## The artificial neural network preformed poorly on the test data getting 48 percent accuracy. It performed best on class 8 (ship) and worst on class 4 (deer). Next we would try a convolution neural network which is more suited to images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIhDk3LKrA1N"
      },
      "source": [
        "# Convolution Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-01T15:43:34.725515Z",
          "start_time": "2020-11-01T15:43:34.707524Z"
        },
        "id": "r6xxOzt4rA1N"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "\n",
        "#datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "# zca_whitening=True\n",
        "\n",
        "#datagen.fit(X_train, seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T20:23:53.964787Z",
          "start_time": "2020-11-05T20:21:42.303435Z"
        },
        "id": "pVL_oo-lrA1Q",
        "scrolled": false,
        "outputId": "0918f3bd-46fb-424f-9ddf-28489829deeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "cnn = Sequential()\n",
        "# Upsampling our input images due to their low resolution to enable or model to detect more patterns\n",
        "#cnn.add(tf.keras.layers.UpSampling2D(size=(2,2)))\n",
        "\n",
        "# data augumentation\n",
        "cnn.add(preprocessing.RandomFlip('horizontal')) # flip left to right\n",
        "#cnn.add(preprocessing.RandomContrast(0.5)) # contrast change by up to 50%\n",
        "\n",
        "# convolution layer\n",
        "cnn.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\n",
        "               padding='same', input_shape=(32, 32, 3)))\n",
        "cnn.add(MaxPool2D((2, 2)))\n",
        "\n",
        "cnn.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "               activation='relu', padding='same'))\n",
        "cnn.add(MaxPool2D((2, 2)))\n",
        "\n",
        "cnn.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "               activation='relu', padding='same'))\n",
        "cnn.add(MaxPool2D((2, 2)))\n",
        "\n",
        "# DNN classifier layer\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(512, activation='relu'))\n",
        "cnn.add(Dropout(0.2))\n",
        "\n",
        "cnn.add(Dense(256, activation='relu'))\n",
        "cnn.add(Dropout(0.2))\n",
        "\n",
        "# cnn.add(BatchNormalization())\n",
        "\n",
        "cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#print(cnn.summary())\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#callback = []\n",
        "def decay(epoch):\n",
        "    \"\"\" This method create the alpha\"\"\"\n",
        "    return 0.001 / (1 + 1 * 30)\n",
        "\n",
        "#callback += [tf.keras.callbacks.LearningRateScheduler(decay, verbose=1)]\n",
        "#callback += [tf.keras.callbacks.ModelCheckpoint('cifar10.h5', save_best_only=True, mode='min')]\n",
        "\n",
        "callback = [tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss')]\n",
        "cnn.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callback, epochs=40, batch_size=128)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.5934 - accuracy: 0.4156 - val_loss: 1.2854 - val_accuracy: 0.5452\n",
            "Epoch 2/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.2017 - accuracy: 0.5695 - val_loss: 1.0616 - val_accuracy: 0.6224\n",
            "Epoch 3/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.0189 - accuracy: 0.6394 - val_loss: 0.9447 - val_accuracy: 0.6720\n",
            "Epoch 4/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.9095 - accuracy: 0.6820 - val_loss: 0.8568 - val_accuracy: 0.6968\n",
            "Epoch 5/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.8379 - accuracy: 0.7080 - val_loss: 0.8396 - val_accuracy: 0.7014\n",
            "Epoch 6/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.7649 - accuracy: 0.7322 - val_loss: 0.7603 - val_accuracy: 0.7270\n",
            "Epoch 7/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.7203 - accuracy: 0.7489 - val_loss: 0.7447 - val_accuracy: 0.7412\n",
            "Epoch 8/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.6760 - accuracy: 0.7633 - val_loss: 0.7021 - val_accuracy: 0.7564\n",
            "Epoch 9/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.6287 - accuracy: 0.7801 - val_loss: 0.7126 - val_accuracy: 0.7586\n",
            "Epoch 10/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.5973 - accuracy: 0.7906 - val_loss: 0.6950 - val_accuracy: 0.7586\n",
            "Epoch 11/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.5630 - accuracy: 0.8028 - val_loss: 0.6796 - val_accuracy: 0.7704\n",
            "Epoch 12/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.5425 - accuracy: 0.8114 - val_loss: 0.6845 - val_accuracy: 0.7684\n",
            "Epoch 13/40\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.5120 - accuracy: 0.8212 - val_loss: 0.6594 - val_accuracy: 0.7776\n",
            "Epoch 14/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.4750 - accuracy: 0.8334 - val_loss: 0.7333 - val_accuracy: 0.7686\n",
            "Epoch 15/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.4626 - accuracy: 0.8378 - val_loss: 0.6728 - val_accuracy: 0.7778\n",
            "Epoch 16/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.4398 - accuracy: 0.8462 - val_loss: 0.6938 - val_accuracy: 0.7784\n",
            "Epoch 17/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.4070 - accuracy: 0.8578 - val_loss: 0.7087 - val_accuracy: 0.7726\n",
            "Epoch 18/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.3909 - accuracy: 0.8627 - val_loss: 0.6919 - val_accuracy: 0.7758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa39411e780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:19:50.605888Z",
          "start_time": "2020-11-02T12:19:48.375469Z"
        },
        "id": "wX7_OYkwrA1U",
        "outputId": "b9bfb04d-1ac0-4caa-89d7-8b86249b171c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cnn.evaluate(X_test, y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6904 - accuracy: 0.7812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6904495358467102, 0.7811999917030334]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87LNFYx5rA1Z"
      },
      "source": [
        "## Results \n",
        "- with same padding, Accuracy: 0.7498 , loss: 1.1980 without data augumentation\n",
        "- with data augumentation, Accuracy: 0.7811999"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T11:24:01.648518Z",
          "start_time": "2020-11-02T11:23:59.898784Z"
        },
        "id": "kSlRb1QQrA1b",
        "outputId": "6caaf2be-c4a8-4c78-c5ba-4818102cb21a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#pred = cnn.predict(X_test)\n",
        "#pred\n",
        "\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T11:25:26.813882Z",
          "start_time": "2020-11-02T11:25:25.353659Z"
        },
        "id": "dTOfLxxHrA1f",
        "outputId": "2ac6a6de-4de7-4ca8-b117-bdda793b41d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred1 = cnn.predict(X_test)\n",
        "\n",
        "y_test = [np.argmax(x) for x in y_test]\n",
        "pred1 = [np.argmax(x) for x in pred1]\n",
        "print(classification_report(y_test, pred1))\n",
        "print('\\n')\n",
        "print(confusion_matrix(y_test, pred1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81      1000\n",
            "           1       0.86      0.89      0.87      1000\n",
            "           2       0.74      0.63      0.68      1000\n",
            "           3       0.56      0.59      0.57      1000\n",
            "           4       0.69      0.77      0.72      1000\n",
            "           5       0.64      0.68      0.66      1000\n",
            "           6       0.78      0.82      0.80      1000\n",
            "           7       0.82      0.79      0.80      1000\n",
            "           8       0.88      0.85      0.87      1000\n",
            "           9       0.86      0.82      0.84      1000\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.76      0.76     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "\n",
            "[[799  21  36  24  28   7   7  14  36  28]\n",
            " [ 10 885   8  10   5   2   8   2  25  45]\n",
            " [ 55   7 629  66  89  66  53  23   7   5]\n",
            " [ 12   3  37 589  73 170  63  31   9  13]\n",
            " [ 16   3  43  54 765  32  43  35   4   5]\n",
            " [ 10   0  25 164  37 681  32  41   4   6]\n",
            " [  4   1  35  63  30  34 817   8   6   2]\n",
            " [ 10   2  16  43  74  52   7 788   1   7]\n",
            " [ 53  26  11  22   4   6  10   4 846  18]\n",
            " [ 11  87   9  21   8   9   5  13  18 819]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXjjQPM2rA1i"
      },
      "source": [
        "## What i noticed is that our cnn classifier performed much better than our ann classifier(71 percent vs 48 percent accuracy). It also performed better on certain image classes and less on others\n",
        "- It performed best on image class 1 (automobile)\n",
        "- it performed performed the least on image class 3 (cat)\n",
        "\n",
        "Comparing the two models,  they both performed well on class 8(ship) and poorly on class 3(cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unJbLyU-rA1j"
      },
      "source": [
        "# Using transfer learning with VGG16 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:58:08.561870Z",
          "start_time": "2020-11-05T17:58:00.930063Z"
        },
        "id": "CwSB6lHprA1j",
        "outputId": "59d34927-37d5-4073-8725-5a8c0868e943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Reload the data\n",
        "\n",
        "#X_train, y_train, y_train_oh = load_train_data()\n",
        "#X_test, y_test, y_test_oh = load_test_data()\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "\n",
        "def preprocess(X, y):\n",
        "    X = X.astype('float32')\n",
        "    #using preprocess VGG16 method by default to scale images and their values\n",
        "    X = preprocess_input(X)\n",
        "    # changind labels to one-hot representation\n",
        "    y = tf.keras.utils.to_categorical(y, 10)\n",
        "    return (X, y)\n",
        "\n",
        "X_train, y_train = preprocess(X_train, y_train)\n",
        "X_test, y_test = preprocess(X_test, y_test)\n",
        "\n",
        "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
        "\n",
        "for train_index, test_index in ss.split(X_train, y_train):\n",
        "    X_train, X_val = X_train[train_index], X_train[test_index]\n",
        "    y_train, y_val = y_train[train_index], y_train[test_index]\n",
        "\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T17:57:56.179711Z",
          "start_time": "2020-11-05T17:57:49.465242Z"
        },
        "id": "PWtHDzrcrA1m",
        "outputId": "381a80a1-e1ab-47c3-bc62-0cd8e9db3183",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load the base of vgg16\n",
        "\n",
        "pt_base = tf.keras.applications.vgg16.VGG16(\n",
        "    include_top=False, weights='imagenet', pooling='max', input_shape=(32, 32, 3))\n",
        "\n",
        "#pt_base.trainable = False"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T19:49:41.295008Z",
          "start_time": "2020-11-05T19:26:39.872399Z"
        },
        "id": "3YzvaL7PrA1r",
        "scrolled": false,
        "outputId": "c6ad2517-f92a-424a-8818-63013ea447f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# attach the head\n",
        "\n",
        "tf_model = Sequential()\n",
        "# Upsampling our images\n",
        "tf_model.add(tf.keras.layers.UpSampling2D(size=(2,2)))\n",
        "#tf_model.add(tf.keras.layers.Conv2DTranspose(3, (3,3),strides=(2,2), padding='same'))\n",
        "\n",
        "# data augumentation\n",
        "tf_model.add(preprocessing.RandomFlip('horizontal')) # flip left to right\n",
        "tf_model.add(preprocessing.RandomContrast(0.5)) # contrast change by up to 50%\n",
        "\n",
        "tf_model.add(pt_base)\n",
        "\n",
        "tf_model.add(Flatten())\n",
        "\n",
        "tf_model.add(Dense(512, activation='relu'))\n",
        "tf_model.add(Dropout(0.2))\n",
        "#tf_model.add(BatchNormalization())\n",
        "\n",
        "tf_model.add(Dense(256, activation='relu'))\n",
        "tf_model.add(Dropout(0.2))\n",
        "#tf_model.add(BatchNormalization())\n",
        "\n",
        "tf_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#print(tf_model.summary())\n",
        "\n",
        "tf_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "callback = []\n",
        "def decay(epoch):\n",
        "    \"\"\" This method create the alpha\"\"\"\n",
        "    return 0.001 / (1 + 1 * 30)\n",
        "\n",
        "callback += [tf.keras.callbacks.LearningRateScheduler(decay, verbose=1)]\n",
        "callback += [tf.keras.callbacks.ModelCheckpoint('cifar10.h5', save_best_only=True, mode='min')]\n",
        "\n",
        "#callback += [tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss')]\n",
        "\n",
        "\n",
        "tf_model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callback, epochs=2, batch_size=128)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 3.2258064516129034e-05.\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_1:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 64, 64, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_1:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 64, 64, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_1:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 64, 64, 3).\n",
            "  2/352 [..............................] - ETA: 44s - loss: 2.8875 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1710s). Check your callbacks.\n",
            "352/352 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9620WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_1:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 64, 64, 3).\n",
            "352/352 [==============================] - 99s 280ms/step - loss: 0.1236 - accuracy: 0.9620 - val_loss: 0.3467 - val_accuracy: 0.9256\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 3.2258064516129034e-05.\n",
            "Epoch 2/2\n",
            "352/352 [==============================] - 100s 283ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.3308 - val_accuracy: 0.9318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa336361f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T19:58:41.005362Z",
          "start_time": "2020-11-05T19:58:04.291805Z"
        },
        "id": "8geXMvxQrA1w",
        "outputId": "ccdd4d97-95aa-4c6c-88dc-c1f9a05d1cdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf_model.evaluate(X_test, y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 8s 25ms/step - loss: 0.3663 - accuracy: 0.9240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.366346150636673, 0.9240000247955322]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7716i9HrA1z"
      },
      "source": [
        "# Result\n",
        "- using a pretrained base - accuracy: 0.9240, loss: 0.3663\n",
        "- using an untrained base - accuracy: 0.80, loss: 0.80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T19:59:44.027109Z",
          "start_time": "2020-11-05T19:59:07.455696Z"
        },
        "id": "RrxqVctWrA10",
        "outputId": "aacf7b81-a786-4909-fa39-4af208c26dc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred2 = tf_model.predict(X_test)\n",
        "\n",
        "pred2 = [np.argmax(x) for x in pred2]\n",
        "y_test = [np.argmax(x) for x in y_test]\n",
        "\n",
        "print(classification_report(y_test, pred2))\n",
        "print('\\n')\n",
        "print(confusion_matrix(y_test, pred2))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_1:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 64, 64, 3).\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93      1000\n",
            "           1       0.94      0.97      0.95      1000\n",
            "           2       0.91      0.92      0.92      1000\n",
            "           3       0.83      0.87      0.85      1000\n",
            "           4       0.95      0.91      0.93      1000\n",
            "           5       0.93      0.79      0.86      1000\n",
            "           6       0.92      0.97      0.94      1000\n",
            "           7       0.96      0.95      0.96      1000\n",
            "           8       0.95      0.96      0.96      1000\n",
            "           9       0.96      0.93      0.94      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "\n",
            "[[958   2   6   1   0   0   0   2  27   4]\n",
            " [  5 972   0   0   0   0   0   0   4  19]\n",
            " [ 24   0 919  14  11   4  20   4   4   0]\n",
            " [ 12   3  15 872   9  38  34   8   5   4]\n",
            " [  8   2  27  18 909   8  14  12   2   0]\n",
            " [  4   2  19 134  14 794  13  16   0   4]\n",
            " [  4   1  10   8   4   1 969   2   0   1]\n",
            " [  9   1   7   6  14   7   1 955   0   0]\n",
            " [ 19   7   2   0   0   0   1   0 964   7]\n",
            " [ 11  46   0   2   0   0   2   0  11 928]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy89l7JrrA2A"
      },
      "source": [
        "# Things i learnt from this project\n",
        "- Data augumentation helps but doesnt have a huge impact on this dataset due to the low pixel resolution (1-3) percent increase\n",
        "- Running the model with a constant learning rate and a model checkpoint callback helped to improve the test accuracy score by 5 percent (from 80% to 85%)\n",
        "- Adding a 2D upsampling layer was the biggest contributor to the model accuracy, it accounted for a little above 7 test percent accuracy increase\n",
        "- Using a 2D upsampling layer gave better performance on this dataset compared to the Conv2D Transpose layer\n",
        "- DropOut regularization help to improve testing and validation accuracy by reducing overfitting\n",
        "- Increasing the 2d upsampling layer's size from (2,2) had no obvious effect on the models test accuracy score\n",
        "- Applying transfer learning by using a pretrained base gave us a lower accuracy score comparared to when the base was untrained (test accuracy in 70s vs test accuracy in 90s)\n",
        "- our Vgg16 (untrained) base with 2d upsampling, constant learning rate, data augumentation and model checkpoint callback gave the best result of 0.91 accuracy score for the cifar 10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRo02Mhf0HJe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}