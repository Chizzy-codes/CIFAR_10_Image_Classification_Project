{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Image_Classification_Using_CIFAR10_Dataset.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKXW_TYCrDk_",
        "outputId": "db75528e-6522-4d21-b1ad-a51e221304bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# needs to be run on colab or kaggle notebook\n",
        "!pip install tensorflow-gpu==2.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.2 in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (2.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (0.35.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (2.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (3.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (1.6.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (1.33.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2) (0.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (1.17.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (50.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (1.7.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (4.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBV-fDpxrAzI"
      },
      "source": [
        "# Importing the needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T10:03:34.394982Z",
          "start_time": "2020-11-02T10:02:23.981967Z"
        },
        "id": "JrhrnQc1rAzK"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-26T13:49:45.900384Z",
          "start_time": "2020-10-26T13:49:45.885385Z"
        },
        "id": "4c2PZo9TrAzU"
      },
      "source": [
        "# The current state of the art performance for this dataset is 99 accuracy (GPipe: Efficient Training of Giant Neural Networks using pipeline parallelism)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T10:03:34.481458Z",
          "start_time": "2020-11-02T10:03:34.434377Z"
        },
        "id": "XGu4nwQ5rAzW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T10:03:36.290054Z",
          "start_time": "2020-11-02T10:03:34.516465Z"
        },
        "id": "uIPg-lXMrAzb",
        "outputId": "7f4d3627-5772-4f1f-eee2-0b4e6c3e3ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Setting random seed for reproducible results\n",
        "\n",
        "from tensorflow.python.client import device_lib \n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 15342753355038304172\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 890164913508442924\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 9502165242947478201\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14755228544\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 10276058362184194520\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srUyiC0-rAzj"
      },
      "source": [
        "# Importing the cifar 10 dataset\n",
        "- Data downloaded from https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:06:00.462133Z",
          "start_time": "2020-11-02T12:06:00.430654Z"
        },
        "id": "VHLVRF1VrAzk"
      },
      "source": [
        "image_size = 32\n",
        "num_channels = 3\n",
        "image_size_flat = image_size * image_size * num_channels\n",
        "num_classes = 10\n",
        "train_files = 5\n",
        "image_per_file = 10000\n",
        "num_train_images = 50000\n",
        "\n",
        "# functions for processing raw cifar file from memory\n",
        "\n",
        "\n",
        "# change the raw data to float and normalize them by dividing by the highest pixel value 255\n",
        "def convert(raw):\n",
        "    raw_float = np.array(raw, dtype=float)\n",
        "    #reshape into 4 dimensions\n",
        "    images = raw_float.reshape(-1, num_channels, image_size, image_size)\n",
        "    # reorder image shape indices\n",
        "    images = images.transpose([0,2,3,1])\n",
        "    return images\n",
        "\n",
        "# load pickle files and return the images and class label\n",
        "def load(filename):\n",
        "    #load pickle files\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = pickle.load(f, encoding='bytes')\n",
        "    \n",
        "    # get raw images and label\n",
        "    raw_images = data[b'data']\n",
        "    labels = np.array(data[b'labels'])\n",
        "    \n",
        "    # convert the images\n",
        "    images = convert(raw_images)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "# load the name of the classes in the cifar-10 dataset\n",
        "def load_class_names():\n",
        "    with open('data/batches.meta', 'rb') as f:\n",
        "        raw = pickle.load(f, encoding='bytes')[b'label_names']\n",
        "    \n",
        "    # convert from binary strings to strings\n",
        "    names = [x.decode('utf-8') for x in raw]\n",
        "    \n",
        "    return names\n",
        "\n",
        "# Load all the 5 batch files of the cifar 10 dataset and combine them in a single training dataset\n",
        "def load_train_data():\n",
        "    # create placeholder image and label arrays\n",
        "    images = np.zeros(shape=[num_train_images, image_size, image_size, num_channels], dtype='float')\n",
        "    labels = np.zeros(shape=[num_train_images], dtype='int')\n",
        "    \n",
        "    # begin index for the current batch\n",
        "    begin = 0\n",
        "    \n",
        "    # for each data file\n",
        "    for i in range(train_files):\n",
        "        # load images and labels\n",
        "        image_batch, label_batch = load('data/data_batch_' + str(i+1))\n",
        "        \n",
        "        # number of images for this batch\n",
        "        num_images = len(image_batch)\n",
        "        \n",
        "        # End-index for the current batch\n",
        "        end = begin + num_images\n",
        "        \n",
        "        # store images in an array\n",
        "        images[begin:end, :] = image_batch\n",
        "        \n",
        "        # store the labels in an array\n",
        "        labels[begin:end] = label_batch\n",
        "        \n",
        "        # the begin index is for the next batch is the current end-index\n",
        "        begin = end\n",
        "        \n",
        "    return images, labels, OneHotEncoder(sparse=False).fit_transform(labels.reshape(-1, 1))\n",
        "\n",
        "\n",
        "# load test data\n",
        "def load_test_data():\n",
        "    images, labels = load('data/test_batch')\n",
        "    \n",
        "    return images, labels, OneHotEncoder(sparse=False).fit_transform(labels.reshape(-1, 1))        "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:06:02.999429Z",
          "start_time": "2020-11-02T12:06:01.367103Z"
        },
        "id": "4gnhMrDurAzv"
      },
      "source": [
        "# load data\n",
        "\n",
        "X_train, y_train, y_train_oh = load_train_data()\n",
        "X_test, y_test, y_test_oh = load_test_data()\n",
        "classes = load_class_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T11:58:49.267889Z",
          "start_time": "2020-11-02T11:58:49.255889Z"
        },
        "id": "eSsV8ICErAz5",
        "outputId": "a0a84b79-e6b6-4cbd-ac0e-9040a98a6a7f"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (10000, 32, 32, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T10:13:12.452997Z",
          "start_time": "2020-11-02T10:13:12.393996Z"
        },
        "id": "arD-Cjy5rAz-"
      },
      "source": [
        "# Alternatively u can load the cifar10 dataset using keras dataset \n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T10:13:12.561992Z",
          "start_time": "2020-11-02T10:13:12.549997Z"
        },
        "id": "cNuE9prRrA0G",
        "outputId": "21b027c4-9a5d-459c-ae3a-545ab4bc4f8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T10:13:12.765420Z",
          "start_time": "2020-11-02T10:13:12.691996Z"
        },
        "id": "9vOflPYIrA0M",
        "outputId": "4ff79533-929d-45be-f272-db5b54ca101b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train.shape, y_test.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 1), (10000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T10:13:20.570389Z",
          "start_time": "2020-11-02T10:13:12.865422Z"
        },
        "id": "N-FXvSFWrA0W",
        "outputId": "f68ea569-b74b-40d1-fe2f-494d31276fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "x = X_train.copy()/255\n",
        "\n",
        "plt.imshow(x[7])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1b48b725f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T10:13:20.712092Z",
          "start_time": "2020-11-02T10:13:20.699064Z"
        },
        "id": "zfh1JeW8rA0b",
        "outputId": "ba757ad5-6331-4b1e-a3a3-e1b18a6bae9b"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T10:13:20.979057Z",
          "start_time": "2020-11-02T10:13:20.809059Z"
        },
        "id": "-BxdkfLmrA0g",
        "outputId": "fa421504-a951-44f6-addf-58b537ed724e"
      },
      "source": [
        "y_train[4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T10:13:21.183146Z",
          "start_time": "2020-11-02T10:13:21.119433Z"
        },
        "id": "iS8YaaI8rA0m"
      },
      "source": [
        "# Reshaping y_train, and y_test\n",
        "y_train1 = y_train.reshape(-1,)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T10:13:21.793299Z",
          "start_time": "2020-11-02T10:13:21.311107Z"
        },
        "id": "u6RhqchtrA0t",
        "outputId": "efb01fcf-4042-4e04-8d5b-caad779b5bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "print(classes[y_train[3]])\n",
        "plt.imshow(x[3])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-82e343e1bac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'classes' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKiDMncmrA0y"
      },
      "source": [
        "# After investigating the images,  we can say that the images would benefit from horizontal flip and random brightness data augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:06:08.541612Z",
          "start_time": "2020-11-02T12:06:07.803871Z"
        },
        "id": "VzMX0H65rA0z"
      },
      "source": [
        "# Normalising the values by dividing by the maximum pixel value (255) if you loaded data from tensorflow library\n",
        "\n",
        "X_train =  X_train/255\n",
        "X_test = X_test/255\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrctLBW6sQBN"
      },
      "source": [
        "# converting the labels values to one hot encoded values\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5Vrk19urA03"
      },
      "source": [
        "## Use sklearn split the training data into train / validate datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:06:09.821724Z",
          "start_time": "2020-11-02T12:06:08.672645Z"
        },
        "id": "KJX_nEGErA04"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
        "\n",
        "for train_index, test_index in ss.split(X_train, y_train):\n",
        "    X_train, X_val = X_train[train_index], X_train[test_index]\n",
        "    y_train, y_val = y_train[train_index], y_train[test_index]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:06:11.343438Z",
          "start_time": "2020-11-02T12:06:11.332482Z"
        },
        "id": "Jr73MZGqrA07",
        "outputId": "53fdd965-8c36-4f15-c72c-e869e8a247da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((45000, 32, 32, 3), (5000, 32, 32, 3), (45000, 10), (5000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-30T12:12:48.297330Z",
          "start_time": "2020-10-30T12:12:48.225331Z"
        },
        "id": "ei_n7hgNrA0-"
      },
      "source": [
        "### use the X_val and y_val as validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30kVVgvTrA0_"
      },
      "source": [
        "# Training models on the train and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9GriaXerA1A"
      },
      "source": [
        "## Using an Artificial Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:10:52.880816Z",
          "start_time": "2020-11-02T12:06:20.965087Z"
        },
        "id": "Hj0Xnw6wrA1A",
        "outputId": "510b3953-f479-417f-b73f-84db7a8cd2e9"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(32,32,3)))\n",
        "model.add(Dense(3072, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "model.fit(X_train, y_train,  validation_data=[X_val, y_val], epochs=40, callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_16 (Flatten)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 3072)              9440256   \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 1024)              3146752   \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 12,597,258\n",
            "Trainable params: 12,597,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/40\n",
            "45000/45000 [==============================] - 19s 429us/sample - loss: 1.8733 - accuracy: 0.3294 - val_loss: 2.2020 - val_accuracy: 0.2298\n",
            "Epoch 2/40\n",
            "45000/45000 [==============================] - 19s 426us/sample - loss: 1.6728 - accuracy: 0.4060 - val_loss: 1.8553 - val_accuracy: 0.3388\n",
            "Epoch 3/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.5845 - accuracy: 0.4387 - val_loss: 1.6614 - val_accuracy: 0.4108\n",
            "Epoch 4/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.5239 - accuracy: 0.4603 - val_loss: 1.6722 - val_accuracy: 0.3964\n",
            "Epoch 5/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.4780 - accuracy: 0.4775 - val_loss: 1.5599 - val_accuracy: 0.4362\n",
            "Epoch 6/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.4316 - accuracy: 0.4939 - val_loss: 1.5354 - val_accuracy: 0.4626\n",
            "Epoch 7/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.3909 - accuracy: 0.5100 - val_loss: 1.5613 - val_accuracy: 0.4490\n",
            "Epoch 8/40\n",
            "45000/45000 [==============================] - 20s 436us/sample - loss: 1.3552 - accuracy: 0.5223 - val_loss: 1.6284 - val_accuracy: 0.4300\n",
            "Epoch 9/40\n",
            "45000/45000 [==============================] - 20s 434us/sample - loss: 1.3226 - accuracy: 0.5357 - val_loss: 1.4824 - val_accuracy: 0.4712\n",
            "Epoch 10/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.2941 - accuracy: 0.5451 - val_loss: 1.8873 - val_accuracy: 0.3846\n",
            "Epoch 11/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.2647 - accuracy: 0.5543 - val_loss: 1.5009 - val_accuracy: 0.4758\n",
            "Epoch 12/40\n",
            "45000/45000 [==============================] - 20s 435us/sample - loss: 1.2324 - accuracy: 0.5679 - val_loss: 1.9744 - val_accuracy: 0.3654\n",
            "Epoch 13/40\n",
            "45000/45000 [==============================] - 19s 431us/sample - loss: 1.2079 - accuracy: 0.5779 - val_loss: 1.4927 - val_accuracy: 0.4628\n",
            "Epoch 14/40\n",
            "45000/45000 [==============================] - 19s 430us/sample - loss: 1.1778 - accuracy: 0.5879 - val_loss: 1.5290 - val_accuracy: 0.4804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x20f6476b888>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:11:32.420306Z",
          "start_time": "2020-11-02T12:11:30.161210Z"
        },
        "id": "caziHbNhrA1E",
        "outputId": "390fa4bc-d57a-4476-cabd-dd7ca69a9298"
      },
      "source": [
        "model.evaluate(X_test, y_test_oh) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 207us/sample - loss: 1.5203 - accuracy: 0.4728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5202577260971069, 0.4728]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-28T21:51:18.224673Z",
          "start_time": "2020-10-28T21:51:16.553436Z"
        },
        "id": "TtZxTDD5rA1I",
        "outputId": "e0901ab6-9a4b-49e0-953e-f10f25edcc02"
      },
      "source": [
        "pred = model.predict(X_test)\n",
        "pred = [np.argmax(x) for x in pred]\n",
        "print(classification_report(y_test, pred))\n",
        "print('\\n')\n",
        "print(confusion_matrix(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.50      0.56      1000\n",
            "           1       0.80      0.31      0.45      1000\n",
            "           2       0.34      0.55      0.42      1000\n",
            "           3       0.32      0.31      0.31      1000\n",
            "           4       0.69      0.12      0.21      1000\n",
            "           5       0.36      0.50      0.42      1000\n",
            "           6       0.46      0.70      0.55      1000\n",
            "           7       0.51      0.65      0.57      1000\n",
            "           8       0.79      0.49      0.60      1000\n",
            "           9       0.50      0.64      0.56      1000\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.54      0.48      0.47     10000\n",
            "weighted avg       0.54      0.48      0.47     10000\n",
            "\n",
            "\n",
            "\n",
            "[[498   8 183  32   1  47  55  66  55  55]\n",
            " [ 40 309  30  65   2  34  63  50  34 373]\n",
            " [ 33   3 547  75  16 104 120  87   3  12]\n",
            " [  5   2 106 308   5 312 171  64   6  21]\n",
            " [ 21   2 347  63 124 106 183 137   7  10]\n",
            " [  5   1 140 173   6 502  92  64   4  13]\n",
            " [  1   1 102  84  10  69 699  24   3   7]\n",
            " [ 14   0  78  70   8 102  51 652   2  23]\n",
            " [118  25  58  37   6  70  41  30 487 128]\n",
            " [ 31  35  22  56   2  44  61  99  12 638]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYKOgeOFrA1M"
      },
      "source": [
        "## The artificial neural network preformed poorly on the test data getting 48 percent accuracy. It performed best on class 8 (ship) and worst on class 4 (deer). Next we would try a convolution neural network which is more suited to images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIhDk3LKrA1N"
      },
      "source": [
        "# Convolution Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-01T15:43:34.725515Z",
          "start_time": "2020-11-01T15:43:34.707524Z"
        },
        "id": "r6xxOzt4rA1N"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "\n",
        "#datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "# zca_whitening=True\n",
        "\n",
        "#datagen.fit(X_train, seed=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:19:42.252627Z",
          "start_time": "2020-11-02T12:17:10.899192Z"
        },
        "scrolled": false,
        "id": "pVL_oo-lrA1Q",
        "outputId": "857b4cb5-8b46-4f10-c547-74ebadded32d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "cnn = Sequential()\n",
        "# Upsampling our input images due to their low resolution to enable or model to detect more patterns\n",
        "#cnn.add(tf.keras.layers.UpSampling2D(size=(2,2)))\n",
        "\n",
        "# data augumentation\n",
        "cnn.add(preprocessing.RandomFlip('horizontal')) # flip left to right\n",
        "#cnn.add(preprocessing.RandomContrast(0.5)) # contrast change by up to 50%\n",
        "\n",
        "# convolution layer\n",
        "cnn.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\n",
        "               padding='same', input_shape=(32, 32, 3)))\n",
        "cnn.add(MaxPool2D((2, 2)))\n",
        "\n",
        "cnn.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "               activation='relu', padding='same'))\n",
        "cnn.add(MaxPool2D((2, 2)))\n",
        "\n",
        "cnn.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "               activation='relu', padding='same'))\n",
        "cnn.add(MaxPool2D((2, 2)))\n",
        "\n",
        "# DNN classifier layer\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(512, activation='relu'))\n",
        "cnn.add(Dropout(0.2))\n",
        "\n",
        "cnn.add(Dense(256, activation='relu'))\n",
        "cnn.add(Dropout(0.2))\n",
        "\n",
        "# cnn.add(BatchNormalization())\n",
        "\n",
        "cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#print(cnn.summary())\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#callback = []\n",
        "def decay(epoch):\n",
        "    \"\"\" This method create the alpha\"\"\"\n",
        "    return 0.001 / (1 + 1 * 30)\n",
        "\n",
        "#callback += [tf.keras.callbacks.LearningRateScheduler(decay, verbose=1)]\n",
        "#callback += [tf.keras.callbacks.ModelCheckpoint('cifar10.h5', save_best_only=True, mode='min')]\n",
        "\n",
        "callback = [tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss')]\n",
        "cnn.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callback, epochs=40, batch_size=128)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.6368 - accuracy: 0.3943 - val_loss: 1.3062 - val_accuracy: 0.5326\n",
            "Epoch 2/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.2318 - accuracy: 0.5560 - val_loss: 1.0770 - val_accuracy: 0.6112\n",
            "Epoch 3/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.0468 - accuracy: 0.6283 - val_loss: 0.9678 - val_accuracy: 0.6552\n",
            "Epoch 4/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.9534 - accuracy: 0.6627 - val_loss: 0.8827 - val_accuracy: 0.6944\n",
            "Epoch 5/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.8619 - accuracy: 0.6944 - val_loss: 0.8402 - val_accuracy: 0.7086\n",
            "Epoch 6/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.7969 - accuracy: 0.7200 - val_loss: 0.8188 - val_accuracy: 0.7116\n",
            "Epoch 7/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.7473 - accuracy: 0.7380 - val_loss: 0.7751 - val_accuracy: 0.7366\n",
            "Epoch 8/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.6974 - accuracy: 0.7538 - val_loss: 0.7394 - val_accuracy: 0.7450\n",
            "Epoch 9/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.7738 - val_loss: 0.7398 - val_accuracy: 0.7428\n",
            "Epoch 10/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.6188 - accuracy: 0.7813 - val_loss: 0.7212 - val_accuracy: 0.7524\n",
            "Epoch 11/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.5813 - accuracy: 0.7965 - val_loss: 0.7471 - val_accuracy: 0.7482\n",
            "Epoch 12/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.5575 - accuracy: 0.8048 - val_loss: 0.7271 - val_accuracy: 0.7496\n",
            "Epoch 13/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.5315 - accuracy: 0.8141 - val_loss: 0.6903 - val_accuracy: 0.7660\n",
            "Epoch 14/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.5047 - accuracy: 0.8224 - val_loss: 0.7786 - val_accuracy: 0.7450\n",
            "Epoch 15/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.4844 - accuracy: 0.8310 - val_loss: 0.6936 - val_accuracy: 0.7690\n",
            "Epoch 16/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.4588 - accuracy: 0.8386 - val_loss: 0.7688 - val_accuracy: 0.7524\n",
            "Epoch 17/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.4393 - accuracy: 0.8443 - val_loss: 0.7374 - val_accuracy: 0.7612\n",
            "Epoch 18/40\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.4169 - accuracy: 0.8541 - val_loss: 0.7331 - val_accuracy: 0.7642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f356345aac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:19:50.605888Z",
          "start_time": "2020-11-02T12:19:48.375469Z"
        },
        "id": "wX7_OYkwrA1U",
        "outputId": "f4e102a0-a32b-4cb0-d1ae-192ac9a4a715",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cnn.evaluate(X_test, y_test)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8112 - accuracy: 0.7634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8112051486968994, 0.7634000182151794]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87LNFYx5rA1Z"
      },
      "source": [
        "## Results \n",
        "- with same padding, Accuracy: 0.7498 , loss: 1.1980 without data augumentation\n",
        "- with data augumentation, Accuracy: 0.7811999"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T11:24:01.648518Z",
          "start_time": "2020-11-02T11:23:59.898784Z"
        },
        "id": "kSlRb1QQrA1b",
        "outputId": "6caaf2be-c4a8-4c78-c5ba-4818102cb21a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#pred = cnn.predict(X_test)\n",
        "#pred\n",
        "\n",
        "y_test"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T11:25:26.813882Z",
          "start_time": "2020-11-02T11:25:25.353659Z"
        },
        "id": "dTOfLxxHrA1f",
        "outputId": "2ac6a6de-4de7-4ca8-b117-bdda793b41d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred1 = cnn.predict(X_test)\n",
        "\n",
        "y_test = [np.argmax(x) for x in y_test]\n",
        "pred1 = [np.argmax(x) for x in pred1]\n",
        "print(classification_report(y_test, pred1))\n",
        "print('\\n')\n",
        "print(confusion_matrix(y_test, pred1))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81      1000\n",
            "           1       0.86      0.89      0.87      1000\n",
            "           2       0.74      0.63      0.68      1000\n",
            "           3       0.56      0.59      0.57      1000\n",
            "           4       0.69      0.77      0.72      1000\n",
            "           5       0.64      0.68      0.66      1000\n",
            "           6       0.78      0.82      0.80      1000\n",
            "           7       0.82      0.79      0.80      1000\n",
            "           8       0.88      0.85      0.87      1000\n",
            "           9       0.86      0.82      0.84      1000\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.76      0.76     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "\n",
            "[[799  21  36  24  28   7   7  14  36  28]\n",
            " [ 10 885   8  10   5   2   8   2  25  45]\n",
            " [ 55   7 629  66  89  66  53  23   7   5]\n",
            " [ 12   3  37 589  73 170  63  31   9  13]\n",
            " [ 16   3  43  54 765  32  43  35   4   5]\n",
            " [ 10   0  25 164  37 681  32  41   4   6]\n",
            " [  4   1  35  63  30  34 817   8   6   2]\n",
            " [ 10   2  16  43  74  52   7 788   1   7]\n",
            " [ 53  26  11  22   4   6  10   4 846  18]\n",
            " [ 11  87   9  21   8   9   5  13  18 819]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXjjQPM2rA1i"
      },
      "source": [
        "## What i noticed is that our cnn classifier performed much better than our ann classifier(71 percent vs 48 percent accuracy). It also performed better on certain image classes and less on others\n",
        "- It performed best on image class 1 (automobile)\n",
        "- it performed performed the least on image class 3 (cat)\n",
        "\n",
        "Comparing the two models,  they both performed well on class 8(ship) and poorly on class 3(cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unJbLyU-rA1j"
      },
      "source": [
        "# Using transfer learning with VGG16 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:26:52.289628Z",
          "start_time": "2020-11-02T12:26:48.773317Z"
        },
        "id": "CwSB6lHprA1j",
        "outputId": "59d34927-37d5-4073-8725-5a8c0868e943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Reload the data\n",
        "\n",
        "#X_train, y_train, y_train_oh = load_train_data()\n",
        "#X_test, y_test, y_test_oh = load_test_data()\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "\n",
        "def preprocess(X, y):\n",
        "    X = X.astype('float32')\n",
        "    #using preprocess VGG16 method by default to scale images and their values\n",
        "    X = preprocess_input(X)\n",
        "    # changind labels to one-hot representation\n",
        "    y = tf.keras.utils.to_categorical(y, 10)\n",
        "    return (X, y)\n",
        "\n",
        "X_train, y_train = preprocess(X_train, y_train)\n",
        "X_test, y_test = preprocess(X_test, y_test)\n",
        "\n",
        "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
        "\n",
        "for train_index, test_index in ss.split(X_train, y_train):\n",
        "    X_train, X_val = X_train[train_index], X_train[test_index]\n",
        "    y_train, y_val = y_train[train_index], y_train[test_index]\n",
        "\n",
        "y_test.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T12:23:25.922344Z",
          "start_time": "2020-11-02T12:23:24.259271Z"
        },
        "id": "PWtHDzrcrA1m"
      },
      "source": [
        "# load the base of vgg16\n",
        "\n",
        "pt_base = tf.keras.applications.vgg16.VGG16(\n",
        "    include_top=False, weights='imagenet', pooling='max', input_shape=(32, 32, 3))\n",
        "\n",
        "#pt_base.trainable = False"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T15:43:14.471398Z",
          "start_time": "2020-11-02T12:29:11.928193Z"
        },
        "scrolled": false,
        "id": "3YzvaL7PrA1r",
        "outputId": "490fc4d4-00a9-42cf-9d65-686af1a6ad57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# attach the head\n",
        "\n",
        "tf_model = Sequential()\n",
        "# Upsampling our images\n",
        "tf_model.add(tf.keras.layers.UpSampling2D(size=(2,2)))\n",
        "#tf_model.add(tf.keras.layers.Conv2DTranspose(3, (3,3),strides=(2,2), padding='same'))\n",
        "\n",
        "# data augumentation\n",
        "tf_model.add(preprocessing.RandomFlip('horizontal')) # flip left to right\n",
        "tf_model.add(preprocessing.RandomContrast(0.5)) # contrast change by up to 50%\n",
        "\n",
        "tf_model.add(pt_base)\n",
        "\n",
        "tf_model.add(Flatten())\n",
        "\n",
        "tf_model.add(Dense(512, activation='relu'))\n",
        "tf_model.add(Dropout(0.2))\n",
        "#tf_model.add(BatchNormalization())\n",
        "\n",
        "tf_model.add(Dense(256, activation='relu'))\n",
        "tf_model.add(Dropout(0.2))\n",
        "#tf_model.add(BatchNormalization())\n",
        "\n",
        "tf_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#print(tf_model.summary())\n",
        "\n",
        "tf_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "callback = []\n",
        "def decay(epoch):\n",
        "    \"\"\" This method create the alpha\"\"\"\n",
        "    return 0.001 / (1 + 1 * 30)\n",
        "\n",
        "callback += [tf.keras.callbacks.LearningRateScheduler(decay, verbose=1)]\n",
        "callback += [tf.keras.callbacks.ModelCheckpoint('cifar10.h5', save_best_only=True, mode='min')]\n",
        "\n",
        "#callback += [tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss')]\n",
        "\n",
        "\n",
        "tf_model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callback, epochs=1, batch_size=128)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 3.2258064516129034e-05.\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_4:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 64, 64, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_4:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 64, 64, 3).\n",
            "352/352 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9634WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_4:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 64, 64, 3).\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.1146 - accuracy: 0.9634 - val_loss: 0.3290 - val_accuracy: 0.9210 - lr: 3.2258e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f353f78a470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T15:45:20.263065Z",
          "start_time": "2020-11-02T15:44:39.176540Z"
        },
        "id": "8geXMvxQrA1w",
        "outputId": "d9389114-3d6f-4ba2-8c3e-21e8df46c551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf_model.evaluate(X_test, y_test)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 8s 25ms/step - loss: 0.3533 - accuracy: 0.9181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3532821536064148, 0.9180999994277954]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7716i9HrA1z"
      },
      "source": [
        "# Result\n",
        "- using a pretrained base - accuracy: 0.9413, loss: 0.1659\n",
        "- using an untrained base - accuracy: 0.80, loss: 0.80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-02T15:50:25.187007Z",
          "start_time": "2020-11-02T15:49:48.274864Z"
        },
        "id": "RrxqVctWrA10",
        "outputId": "f20e96a6-6432-4820-8337-efa26ad0308c"
      },
      "source": [
        "pred2 = tf_model.predict(X_test)\n",
        "\n",
        "pred2 = [np.argmax(x) for x in pred2]\n",
        "y_test = [np.argmax(x) for x in y_test]\n",
        "\n",
        "print(classification_report(y_test, pred2))\n",
        "print('\\n')\n",
        "print(confusion_matrix(y_test, pred2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-109-84c003ba95f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpred2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   1927\u001b[0m     \"\"\"\n\u001b[0;32m   1928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1929\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1931\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 91\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy89l7JrrA2A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}